import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle, io, json, h5py, joblib

from sklearn.datasets import load_iris
from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score

st.set_page_config(page_title="Logistic Regression CV + GridSearch", layout="wide")

st.title("ğŸ” Logistic Regression + äº¤å‰é©—è­‰ + GridSearchCV")

# -----------------------------
# Sidebar: data source
# -----------------------------
st.sidebar.header("ğŸ“‚ è³‡æ–™ä¾†æº")
data_source = st.sidebar.radio("é¸æ“‡è³‡æ–™ä¾†æº", ["Irisï¼ˆäºŒå…ƒï¼‰", "ä¸Šå‚³ CSV"], index=0)

def load_iris_binary():
    iris = load_iris(as_frame=True)
    df = iris.frame.copy()
    df = df[df["target"] < 2].reset_index(drop=True)  # setosa vs versicolor
    df["target"] = df["target"].astype(int)
    return df, "target"

df = None
target_col = None

if data_source == "Irisï¼ˆäºŒå…ƒï¼‰":
    df, target_col = load_iris_binary()
    st.subheader("Irisï¼ˆåƒ… setosa èˆ‡ versicolorï¼‰")
    st.dataframe(df.head())
else:
    file = st.sidebar.file_uploader("ä¸Šå‚³ CSV æª”", type=["csv"])
    if file is not None:
        df = pd.read_csv(file)
        st.subheader("å·²ä¸Šå‚³è³‡æ–™ï¼ˆå‰ 5 ç­†ï¼‰")
        st.dataframe(df.head())
        # select target column
        with st.sidebar:
            target_col = st.selectbox("é¸æ“‡ç›®æ¨™æ¬„ (target)", options=df.columns, index=len(df.columns)-1)
    else:
        st.info("è«‹æ–¼å´æ¬„ä¸Šå‚³ CSVã€‚")
        st.stop()

# -----------------------------
# Sidebar: feature selection
# -----------------------------
st.sidebar.header("ğŸ”§ ç‰¹å¾µèˆ‡é è™•ç†")
if df is not None and target_col is not None:
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    feature_candidates = [c for c in numeric_cols if c != target_col]
    if len(feature_candidates) == 0:
        st.error("æ‰¾ä¸åˆ°å¯ç”¨çš„æ•¸å€¼ç‰¹å¾µæ¬„ã€‚è«‹ç¢ºèªè³‡æ–™æˆ–è½‰æ›æ¬„ä½å‹æ…‹ã€‚")
        st.stop()

    selected_features = st.sidebar.multiselect(
        "é¸æ“‡ç‰¹å¾µæ¬„ï¼ˆè‡³å°‘ 1 å€‹ï¼Œè‹¥é¸ 2 å€‹å¯è¦–è¦ºåŒ–æ±ºç­–é‚Šç•Œï¼‰",
        options=feature_candidates,
        default=feature_candidates[:2] if len(feature_candidates)>=2 else feature_candidates
    )

    if len(selected_features) == 0:
        st.warning("è«‹è‡³å°‘é¸æ“‡ 1 å€‹ç‰¹å¾µæ¬„ã€‚")
        st.stop()

    use_standardize = st.sidebar.checkbox("ä½¿ç”¨ StandardScaler æ¨™æº–åŒ–", value=True)

# -----------------------------
# Sidebar: train/test split & CV
# -----------------------------
st.sidebar.header("ğŸ§ª åˆ‡åˆ†èˆ‡äº¤å‰é©—è­‰è¨­å®š")
test_size = st.sidebar.slider("æ¸¬è©¦é›†æ¯”ä¾‹", 0.1, 0.5, 0.2, 0.05)
cv_folds = st.sidebar.slider("äº¤å‰é©—è­‰æŠ˜æ•¸ (K)", 3, 10, 5, 1)
random_state = st.sidebar.number_input("random_state", min_value=0, value=42, step=1)

# -----------------------------
# Sidebar: Scoring
# -----------------------------
st.sidebar.header("ğŸ è©•åˆ†æŒ‡æ¨™")
scoring = st.sidebar.selectbox(
    "scoring",
    options=["accuracy", "f1", "roc_auc"],
    index=0,
    help="è‹¥è³‡æ–™ä¸å¹³è¡¡ï¼Œå»ºè­°å˜—è©¦ f1 æˆ– roc_aucï¼ˆåƒ…äºŒå…ƒé©ç”¨ï¼‰"
)

# -----------------------------
# Sidebar: Grid parameters
# -----------------------------
st.sidebar.header("ğŸ§­ è¶…åƒæ•¸æœå°‹ï¼ˆGridSearchï¼‰")
use_grid = st.sidebar.checkbox("å•Ÿç”¨ GridSearchCV", value=True)

# C range
st.sidebar.markdown("**C å€¼ç¯„åœï¼ˆå°æ•¸åˆ»åº¦ï¼‰**")
c_min_exp, c_max_exp = st.sidebar.slider("log10(C) ç¯„åœ", -3, 3, (-3, 3))
c_points = st.sidebar.slider("C å–æ¨£é»æ•¸", 3, 15, 7)
C_values = np.logspace(c_min_exp, c_max_exp, c_points)

solvers = st.sidebar.multiselect("solver", ["liblinear", "saga"], default=["liblinear", "saga"])
penalties = st.sidebar.multiselect("penalty", ["l1", "l2", "elasticnet"], default=["l1", "l2", "elasticnet"])
l1_ratios = st.sidebar.multiselect("l1_ratio (åƒ… elasticnet)", [0.1, 0.5, 0.9], default=[0.5])
class_weight_opt = st.sidebar.selectbox("class_weight", [None, "balanced"], index=0)

# Threshold
st.sidebar.header("ğŸ“ˆ æ±ºç­–é–¾å€¼ï¼ˆé æ¸¬æ©Ÿç‡>é–¾å€¼åˆ¤ç‚ºæ­£é¡ï¼‰")
threshold = st.sidebar.slider("threshold", 0.1, 0.9, 0.5, 0.05)

# -----------------------------
# Prepare data
# -----------------------------
X = df[selected_features].values
y = df[target_col].values

# ensure binary labels for f1/roc_auc
unique_y = np.unique(y)
if scoring in ("f1", "roc_auc") and len(unique_y) != 2:
    st.warning("é¸æ“‡äº†äºŒå…ƒè©•åˆ†æŒ‡æ¨™ï¼Œä½†ç›®æ¨™æ¬„ä¸æ˜¯äºŒå…ƒã€‚å°‡æ”¹ç”¨ accuracyã€‚")
    scoring = "accuracy"

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=test_size, stratify=y if len(unique_y)>1 else None, random_state=random_state
)

# -----------------------------
# Build pipeline
# -----------------------------
steps = []
if use_standardize:
    steps.append(("scaler", StandardScaler()))
steps.append(("clf", LogisticRegression(max_iter=5000)))
pipe = Pipeline(steps)

# Parameter grid
param_grid = []
if use_grid:
    # Two dicts to respect solver/penalty compatibility
    if "liblinear" in solvers:
        param_grid.append({
            "clf__solver": ["liblinear"],
            "clf__penalty": [p for p in penalties if p in ("l1", "l2")],
            "clf__C": C_values,
            "clf__class_weight": [class_weight_opt]
        })
    if "saga" in solvers:
        grid_saga = {
            "clf__solver": ["saga"],
            "clf__penalty": [p for p in penalties if p in ("l1", "l2", "elasticnet")],
            "clf__C": C_values,
            "clf__class_weight": [class_weight_opt]
        }
        if "elasticnet" in grid_saga["clf__penalty"]:
            grid_saga["clf__l1_ratio"] = l1_ratios if len(l1_ratios) > 0 else [0.5]
        param_grid.append(grid_saga)

# -----------------------------
# Train
# -----------------------------
cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_state)

if use_grid and len(param_grid) > 0:
    grid = GridSearchCV(
        estimator=pipe,
        param_grid=param_grid,
        scoring=scoring,
        cv=cv,
        n_jobs=-1,
        verbose=0,
        refit=True
    )
    grid.fit(X_train, y_train)
    best_est = grid.best_estimator_
    best_params = grid.best_params_
    best_cv_mean = grid.best_score_
    st.success(f"æœ€ä½³CVåˆ†æ•¸ ({scoring}): {best_cv_mean:.4f}")
    st.write("æœ€ä½³åƒæ•¸çµ„åˆï¼š", best_params)

    # Top-N results
    with st.expander("ğŸ” æŸ¥çœ‹å‰ 5 ååƒæ•¸çµ„åˆ"):
        means = grid.cv_results_["mean_test_score"]
        stds = grid.cv_results_["std_test_score"]
        params = grid.cv_results_["params"]
        top = sorted(zip(means, stds, params), key=lambda x: x[0], reverse=True)[:5]
        top_df = pd.DataFrame(
            [dict(score_mean=m, score_std=s, **p) for m, s, p in top]
        )
        st.dataframe(top_df)
else:
    # No grid search: just fit the pipeline
    best_est = pipe.fit(X_train, y_train)
    st.info("æœªå•Ÿç”¨ GridSearchCVï¼Œå·²ç›´æ¥è¨“ç·´åŸºæœ¬æ¨¡å‹ã€‚")
    best_params = None

# -----------------------------
# Evaluate
# -----------------------------
st.header("ğŸ“Š æ¨¡å‹è©•ä¼°ï¼ˆæ¸¬è©¦é›†ï¼‰")


y_prob = None
if len(np.unique(y_train)) == 2:
    # Binary: allow custom threshold
    y_prob = best_est.predict_proba(X_test)[:, 1]
    y_pred = (y_prob > threshold).astype(int)
else:
    y_pred = best_est.predict(X_test)

acc = accuracy_score(y_test, y_pred)
st.write(f"**Accuracy:** {acc:.4f}")

if len(np.unique(y_train)) == 2 and y_prob is not None:
    try:
        auc = roc_auc_score(y_test, y_prob)
        st.write(f"**ROC AUC (for reference):** {auc:.4f}")
    except Exception:
        pass

st.write("**æ··æ·†çŸ©é™£**")
st.dataframe(pd.DataFrame(confusion_matrix(y_test, y_pred)))

st.write("**åˆ†é¡å ±å‘Š**")
report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
st.dataframe(pd.DataFrame(report).T)

# -----------------------------
# Visualization (only when exactly 2 numeric features selected)
# -----------------------------
if len(selected_features) == 2:
    st.header("ğŸ—ºï¸ æ±ºç­–é‚Šç•Œï¼ˆ2 ç‰¹å¾µï¼‰")

    # In this app, X_train/X_test already correspond to selected_features in order
    X2_train = X_train[:, [0, 1]]
    X2_test = X_test[:, [0, 1]]

    # Build model using the learned LR settings
    steps2 = []
    if use_standardize:
        steps2.append(("scaler", StandardScaler()))

    # Extract LR config from fitted pipeline
    lr_step = None
    for name, step in best_est.steps:
        if isinstance(step, LogisticRegression):
            lr_step = step
            break
    if lr_step is None:
        lr_step = LogisticRegression(max_iter=5000)

    steps2.append(("clf", LogisticRegression(
        max_iter=lr_step.max_iter,
        solver=lr_step.solver,
        penalty=lr_step.penalty,
        C=lr_step.C,
        l1_ratio=getattr(lr_step, "l1_ratio", None),
        class_weight=lr_step.class_weight
    )))
    pipe2 = Pipeline(steps2)
    pipe2.fit(X2_train, y_train)

    x_min, x_max = X2_train[:, 0].min() - 1.0, X2_train[:, 0].max() + 1.0
    y_min, y_max = X2_train[:, 1].min() - 1.0, X2_train[:, 1].max() + 1.0
    xx, yy = np.meshgrid(
        np.linspace(x_min, x_max, 300),
        np.linspace(y_min, y_max, 300)
    )
    grid_points = np.c_[xx.ravel(), yy.ravel()]
    if len(np.unique(y_train)) == 2:
        Z = pipe2.predict_proba(grid_points)[:, 1].reshape(xx.shape)
    else:
        Z = pipe2.predict(grid_points).reshape(xx.shape)

    fig = plt.figure(figsize=(6, 5))
    cs = plt.contourf(xx, yy, Z, levels=20, alpha=0.6)
    if len(np.unique(y_train)) == 2:
        plt.contour(xx, yy, Z, levels=[0.5])
    plt.scatter(X2_train[:, 0], X2_train[:, 1], marker='o', label='train')
    plt.scatter(X2_test[:, 0], X2_test[:, 1], marker='x', label='test')
    plt.xlabel(selected_features[0])
    plt.ylabel(selected_features[1])
    plt.title("Decision Boundary (Logistic Regression)")
    plt.legend()
    st.pyplot(fig)
else:
    st.info("è‹¥å‰›å¥½é¸æ“‡ **2 å€‹æ•¸å€¼ç‰¹å¾µ**ï¼Œå°‡é¡¯ç¤ºæ±ºç­–é‚Šç•Œåœ–ã€‚")

# -----------------------------
# Downloads
# -----------------------------
st.header("ğŸ’¾ ä¸‹è¼‰æ¨¡å‹")


col1, col2, col3 = st.columns(3)

with col1:
    pkl_bytes = pickle.dumps(best_est)
    st.download_button(
        label="ä¸‹è¼‰ .pkl",
        data=pkl_bytes,
        file_name="model.pkl",
        mime="application/octet-stream"
    )

with col2:
    buf = io.BytesIO()
    joblib.dump(best_est, buf)
    buf.seek(0)
    st.download_button(
        label="ä¸‹è¼‰ .joblib",
        data=buf.getvalue(),
        file_name="model.joblib",
        mime="application/octet-stream"
    )

with col3:
    # NOTE: For sklearn, .h5 is not native. We export a lightweight HDF5 containing parameters.
    # This is mainly for interoperability or inspection, not a drop-in model file.
    h5buf = io.BytesIO()
    with h5py.File(h5buf, "w") as h5f:
        grp = h5f.create_group("model_info")
        grp.attrs["framework"] = "scikit-learn"
        grp.attrs["estimator"] = str(best_est)
        grp.create_dataset("selected_features", data=np.array(selected_features, dtype="S"))
        # Try to extract LR step to save coefficients/intercept/classes
        try:
            lr = None
            for name, step in best_est.steps:
                if isinstance(step, LogisticRegression):
                    lr = step
                    break
            if lr is not None:
                lr_grp = h5f.create_group("logistic_regression")
                lr_grp.create_dataset("coef_", data=lr.coef_)
                lr_grp.create_dataset("intercept_", data=lr.intercept_)
                lr_grp.create_dataset("classes_", data=lr.classes_)
                # store config
                cfg = dict(
                    solver=lr.solver,
                    penalty=lr.penalty,
                    C=float(lr.C),
                    max_iter=int(lr.max_iter),
                    class_weight=("balanced" if lr.class_weight == "balanced" else None),
                    l1_ratio=(None if getattr(lr, "l1_ratio", None) is None else float(lr.l1_ratio))
                )
                lr_grp.attrs["config_json"] = json.dumps(cfg)
        except Exception as e:
            grp.attrs["warning"] = f"Could not extract LR parameters: {e}"
    h5buf.seek(0)
    st.download_button(
        label="ä¸‹è¼‰ .h5ï¼ˆåƒæ•¸å°å‡ºï¼‰",
        data=h5buf.getvalue(),
        file_name="model_params.h5",
        mime="application/octet-stream",
        help="æ­¤ .h5 æª”åƒ…å„²å­˜ä¿‚æ•¸/çµæ§‹è³‡è¨Šï¼Œéå¯ç›´æ¥ `.predict()` çš„ sklearn ç‰©ä»¶ã€‚"
    )
